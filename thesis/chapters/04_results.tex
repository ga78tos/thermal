% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Results}\label{chapter:results}
Based on the thermal profiles which were determined experimentally in \ref{t_prof} the GMPT algorithm will be used to generate schedules for different workloads. Then, for those same workloads, schedules are also derived by the PMPT algorithm \cite{Cheng2015}. These are DPM schedules that also satisfy hard real-time constraints and were calculated by brute force to find the best ratio between the active and inactive CPU state. This produces very accurate data but also requires lengthy computations, resulting in a large overhead. The two approaches will be employed twice, once for a single-task model and once for a multi-task model. The data returned by these experiments will serve to:
\begin{enumerate}[label=(\roman*)]
\item analyze the feasibility of the GMPT algorithm by assessing the performance of its schedules in an environment that closely resembles a typical embedded real-time system.
\item compare the GMPT schedules to another state of the art approach by examining its effect on the thermal development of the processor.
\end{enumerate}
\section{Platform: Notebook}
Two sets of experiments were run on the notebook platform. The first set served to compare the solutions proposed by the two methods within a single-task simulation. In the second set the algorithms tackled a multi-task simulation.
\subsection{Single-Task}
The schedules generated by the two algorithms for 15 different workloads can be seen in \autoref{app:t_pmpt_n} (Appendix). This table clearly demonstrates that the increased effort that is invested in the computation of DVFS schedules doesn't necessarily translate into a more complex schedule. In many cases the schedule derived by GMPT contains only two frequency switches which indicates that the overhead for such schedules won't be much larger than for PMPT schedules (if the frequency setting of the first and last timeslot within a GMPT schedule match, no switch is required between the periods). The thermal behavior of the processor for the GMPT and PMPT schedules is displayed in \autoref{fig:i_eva_gp_n}.\\
\input{figures/eval_gp_notebook}
The first few schedules show how a high workload can drastically affect the CPU temperature. Overall both approaches display a similar pattern, naturally struggling with the very high workloads and eventually stabilizing at lower workloads.\\
\hspace*{0.5ex}\hspace{0.5ex} The biggest performance gap between GMPT and PMPT solutions are the high workloads (\autoref{tab:t_medgp_n}). This can be attributed to the cubic influence the frequency/voltage has on the processor power dissipation. Being able to lower the frequency and voltage for a long time period, even if just by a small amount, can have a major impact on the thermal behavior of the platform especially in high frequency ranges. This primarily affects high workloads since in these cases the CPU runs at the maximum frequency for extended periods. This effect is also reflected in the previously computed thermal profile of the notebook.\\
\input{figures/eval_gp_table}
Toward lower workloads the difference between the two approaches becomes less clear with the GMPT schedules occasionally resulting in higher peak temperatures. This can, at least in part, be attributed to the increased effectiveness of the idle times due to their longer duration for low workloads. Additionally, with decreasing workloads the peak temperature approaches and converges toward the idle temperature. The performance gap between the two approaches will therefore inevitably shrink. Concerning the accuracy of the measurements \autoref{fig:i_eva_gpbar_n} demonstrates that the spread of data points is very similar for both approaches and that the mean peak temperatures for GMPT and PMPT at low workloads often lie within the spread of each others data points. The performance gap at these workload levels is therefore not considered significant.
\input{figures/eval_gpbar_notebook}
\subsection{Multi-Task}
The comparison within the multi-task simulation is also based on 15 schedules designed for different workloads, they are reported in \autoref{app:t_ampt_n} (Appendix). Similarly to the previous comparison, many of the GMPT schedules do not require any more frequency switches than the PMPT schedules, diminishing the overhead. \autoref{fig:i_eva_ga_n} depicts the thermal reaction of the notebook platform for the new schedules generated by GMPT and PMPT.\\
\input{figures/eval_ga_notebook}
The overall thermal pattern for both scheduling approaches is again similar, however, contrary to the first comparison, the peak temperature reached by the DPM schedules seem to converge toward a higher temperature level (or at least converge significantly slower). The performance gap for very high workloads is not as big as for the prior comparison but for very low workloads a considerable difference between the two approaches is still visible (\autoref{tab:t_medga_n}).\\
\input{figures/eval_ga_table}
The idle temperature of the platform obviously doesn't change depending on the amount of tasks. As visualized in \autoref{fig:i_eva_gabar_n}, the spread of the data points is also too tight to attribute this discrepancy to pure measurement inaccuracies. This phenomenon is probably mostly owed to the fact that a schedule consisting of multiple tasks cannot always be condensed down into one continuous execution block if all tasks run at maximum speed. This means that PMPT must ensure that the active times are sufficiently large to accommodate all tasks. This could lead to situations where during some of the active time, no tasks are running (as they are either finished, haven't been started or cannot start yet). For the GMPT approach this does not constitute a problem since the execution times of each tasks can be "stretched" so that every task finishes as closely as possible to the start of the next task. Under these circumstances GMPT clearly provides the better results from a pure peak temperature minimization standpoint.
\input{figures/eval_gabar_notebook}
\section{Platform: Raspberry Pi 3B}
On the Raspberry Pi platform the GMPT and PMPT algorithms were again applied to calculate schedules for single- and multi-task simulations.
\subsection{Single-Task}
The schedules generated by GMPT and PMPT for the different workloads in the single-task environment can be seen in \autoref{app:t_smpt_pi} (Appendix). Even though it is not as pronounced as on the notebook platform, some of the schedules that were computed by the genetic algorithm also require only few frequency changes. For these schedules the influence of the overhead is expected to be very similar for both approaches. However, overall the schedules for the Raspberry Pi do seem to require more frequency changes than those on used on the Notebook. This can at least in part be attributed to the smaller temperature range available on this platform, which likely makes it more difficult to determine which frequency is best at any given point in time.\\
\input{figures/eval_gp_s_pi}
\autoref{fig:i_eva_gp_s_pi} displays the thermal behavior of the Raspberry Pi CPU for the two kinds of schedules. As indicated by the thermal profiles, the changes in temperature are not as large as on the notebook platform but the temperature development through the 15 schedules still resembles a similar pattern.\\
\begin{table}[H]
 \centering
 \caption[Single-Task median results Raspberry]{Median peak temperature for all workloads and their performance gap}\label{tab:t_sedgp_pi}
 \setlength\tabcolsep{5pt}
 \resizebox{\textwidth}{!}{%
 \begin{tabular}{|l||c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} 
 \hline
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \\ [0.2ex] 
 \hline\hline
GMPT & 49,7 & 49,2 & 46,9 & 46,5 & 46,2 & 45,8 & 45,6 & 45,6 & 45,6 & 45,5 & 45,5 & 45,4 & 45,4 & 45,3 & 45,4 \\
\hline
PMPT & 50,5 & 49,5 & 47,1 & 47,0 & 46,7 & 45,9 & 45,6 & 45,5 & 45,5 & 45,2 & 45,3 & 45,4 & 45,3 & 45,3 & 45,3 \\
\hline
P.Gap & -0,8 & -0,3 & -0,2 & -0,5 & -0,5 & -0,1 & 0,0 & 0,1 & 0,1 & 0,3 & 0,2 & 0,0 & 0,1 & 0,0 & 0,1 \\
\hline
\end{tabular}}
\end{table}
The difference in peak temperature for the two scheduling approaches is much smaller than observed on the notebook platform (\autoref{tab:t_sedgp_pi}). While the small temperature range may contribute to this, the behavior appears to differ from the observations on the other platform. The temperatures achieved by the two algorithms doesn't diverge as strongly, even for the highest workload, the GMPT schedules do not appear to provide a strong benefit. As indicated by \autoref{fig:i_eva_ga_n}, the spread of the data points doesn't differ by a significant amount between the two scheduling approaches. This shows that the frequency changes of the DVFS schedules do not add any instability to the achieved temperature.\\
\hspace*{0.5ex}\hspace{0.5ex} On this platform the benefit of the GMPT schedules isn't as pronounced as it appeared on the notebook. In this single-task simulation the peak temperature achieved for low workloads is, to all intents and purposes, the same for both methods, and even for very high workloads, while there is a difference, it doesn't appear to be very strong.
\input{figures/eval_sbar_pi}
\subsection{Multi-Task}
In the multi-task environment on the Raspberry Pi the GMPT schedules are the most complex (\autoref{app:t_mmpt_pi}). They require more frequency changes than those under any of the previous conditions. Based on previous observations, this behavior can partly be traced back to the smaller available frequency and temperature range inherent to the platform in combination with the increased challenge of scheduling multiple tasks.\\
\hspace*{0.5ex}\hspace{0.5ex} As illustrated by \autoref{fig:i_eva_gp_m_pi} the temperature development over different workloads follows the familiar pattern observed in previous experiments. The peak temperatures achieved by both algorithms is similar throughout all workloads with schedules for low workload achieving practically the same temperature for both approaches. Only the highest workloads yield a noticeable difference for the two scheduling methods, however, like in the single-task simulations, the difference between the two struggles to reach even $1^\circ C$ (\autoref{tab:t_medgp_pi}).\\
\hspace*{0.5ex}\hspace{0.5ex} Similarly to the multi-task simulation on the notebook, the peak temperatures for the PMPT schedules appear to converge toward a slightly higher temperature but unlike on the other platform it is not clear if this difference can be considered significant.\\
\input{figures/eval_gp_m_pi}
\begin{table}[H]
 \centering
 \caption[Multi-Task median results Raspberry]{Median peak temperature for all workloads and their performance gap}\label{tab:t_medgp_pi}
 \setlength\tabcolsep{5pt}
 \resizebox{\textwidth}{!}{%
 \begin{tabular}{|l||c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} 
 \hline
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \\ [0.2ex] 
 \hline\hline
GMPT & 50,3 & 49,4 & 48,2 & 47,6 & 47,3 & 46,9 & 46,6 & 46,6 & 46,7 & 46,5 & 46,6 & 46,5 & 46,6 & 46,4 & 46,4 \\
\hline
PMPT & 50,6 & 49,6 & 49,0 & 47,9 & 47,4 & 47,1 & 46,9 & 46,8 & 46,8 & 46,8 & 46,7 & 46,7 & 46,6 & 46,7 & 46,7 \\
\hline
P.Gap & -0,3 & -0,2 & -0,8 & -0,3 & -0,1 & -0,2 & -0,3 & -0,2 & -0,1 & -0,3 & -0,1 & -0,2 & 0,0 & -0,3 & -0,3 \\
\hline
\end{tabular}}
\end{table}
The comparison provided by \autoref{fig:i_eva_mabar_pi} further shows how close the peak temperatures reached by both scheduling approaches are. For most of the lower workloads the error bars indicate that the difference of the medians is not big enough to clearly demonstrate the behavior observed on the notebook. Regarding the higher workloads, the difference in peak temperature is larger and does demonstrate that the schedules derived by GMPT can provide a benefit under some circumstances. Ultimately, whether the slightly lower temperature for the DVFS schedules justifies their application, considering the increased effort associated with their computation, needs to be evaluated on a case-by-case basis.\\
\hspace*{0.5ex}\hspace{0.5ex} Before drawing a definite conclusion on this platform, the overhead introduced by the framework needs to be taken into account. The analysis in \autoref{chap:ohd_a} has shown, that the frequency changes cause the largest overhead. This mostly affects the DVFS schedules and since it is not clear how highly the CPU is loaded during the execution of the frequency switch, it is not entirely predictable how these lengthy changes affect the temperature development. The results on this platform can therefore not be considered as reliable as the ones from the notebook.
\input{figures/eval_mbar_pi}
\section{Assessment}
Both the single-task and the multi-task simulations have shown that the GMPT algorithm can yield schedules that provide a significant benefit in minimizing the CPU peak temperature, especially for high workloads. The DVFS schedules appear to handle the challenges in multi-task environments especially well when compared to the PMPT solutions (based on evidence provided by the notebook experiments). Here these schedules manage to minimize the peak temperature better than their DPM counterparts throughout all workloads.\\
\hspace*{0.5ex}\hspace{0.5ex} A further factor that could influence the algorithm choice is the time it takes to compute the schedules. The PMPT algorithm is about one order of magnitude faster than the GMPT algorithm. If the schedules are always computed beforehand, this is not an issue, if, however, the static scheduling scheme needs to be adapted at some point during its execution the PMPT approach may be more advantageous.\\
\hspace*{0.5ex}\hspace{0.5ex} The adjustments performed on the notebook and the framework itself succeeded in recreating an environment that resembles a typical hard real-time system. The results provided by the experiments on this platform are therefore considered very reliable and their yields are assumed to be an accurate representation of the performance of both algorithms. The adjustments for the Raspberry Pi on the other hand haven't been as successful. The smaller frequency and temperature range available on this platform makes the comparison of the two approaches undoubtedly more difficult. Additionally, the overhead introduced by the framework is considerably larger than on the notebook, which makes it difficult to draw a clear conclusion regarding the temperature results. Overall the results on this platform cannot be considered as trustworthy as the ones from the notebook. They still provide some evidence that supports the conclusions drawn from the first platform, but when analyzed independently the results are mostly inconclusive.